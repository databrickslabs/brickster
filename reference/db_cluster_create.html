<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Create a Cluster — db_cluster_create • brickster</title><!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Create a Cluster — db_cluster_create"><meta name="description" content="Create a Cluster"><meta property="og:description" content="Create a Cluster"><meta property="og:image" content="https://databrickslabs.github.io/brickster/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">brickster</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.2.13</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/cluster-management.html">Cluster Management</a></li>
    <li><a class="dropdown-item" href="../articles/managing-jobs.html">Job Management</a></li>
    <li><a class="dropdown-item" href="../articles/remote-repl.html">Databricks REPL</a></li>
    <li><a class="dropdown-item" href="../articles/setup-auth.html">Connect to a Databricks Workspace</a></li>
    <li><a class="dropdown-item" href="../articles/sql-backend.html">`{DBI}`/`{dbplyr}` backend</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/databrickslabs/brickster/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch"><li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Create a Cluster</h1>
      <small class="dont-index">Source: <a href="https://github.com/databrickslabs/brickster/blob/main/R/clusters.R" class="external-link"><code>R/clusters.R</code></a></small>
      <div class="d-none name"><code>db_cluster_create.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Create a Cluster</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">db_cluster_create</span><span class="op">(</span></span>
<span>  <span class="va">name</span>,</span>
<span>  <span class="va">spark_version</span>,</span>
<span>  <span class="va">node_type_id</span>,</span>
<span>  num_workers <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  autoscale <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  spark_conf <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  cloud_attrs <span class="op">=</span> <span class="fu"><a href="aws_attributes.html">aws_attributes</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  driver_node_type_id <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  custom_tags <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  init_scripts <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  spark_env_vars <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  autotermination_minutes <span class="op">=</span> <span class="fl">120</span>,</span>
<span>  log_conf <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  ssh_public_keys <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  driver_instance_pool_id <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  instance_pool_id <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  idempotency_token <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  enable_elastic_disk <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  apply_policy_default_values <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  enable_local_disk_encryption <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  docker_image <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  policy_id <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  kind <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"CLASSIC_PREVIEW"</span><span class="op">)</span>,</span>
<span>  data_security_mode <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"NONE"</span>, <span class="st">"SINGLE_USER"</span>, <span class="st">"USER_ISOLATION"</span>, <span class="st">"LEGACY_TABLE_ACL"</span>,</span>
<span>    <span class="st">"LEGACY_PASSTHROUGH"</span>, <span class="st">"LEGACY_SINGLE_USER"</span>, <span class="st">"LEGACY_SINGLE_USER_STANDARD"</span>,</span>
<span>    <span class="st">"DATA_SECURITY_MODE_STANDARD"</span>, <span class="st">"DATA_SECURITY_MODE_DEDICATED"</span>,</span>
<span>    <span class="st">"DATA_SECURITY_MODE_AUTO"</span><span class="op">)</span>,</span>
<span>  host <span class="op">=</span> <span class="fu"><a href="db_host.html">db_host</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  token <span class="op">=</span> <span class="fu"><a href="db_token.html">db_token</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  perform_request <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-name">name<a class="anchor" aria-label="anchor" href="#arg-name"></a></dt>
<dd><p>Cluster name requested by the user. This doesn’t have to be
unique. If not specified at creation, the cluster name will be an empty
string.</p></dd>


<dt id="arg-spark-version">spark_version<a class="anchor" aria-label="anchor" href="#arg-spark-version"></a></dt>
<dd><p>The runtime version of the cluster. You can retrieve a
list of available runtime versions by using <code><a href="db_cluster_runtime_versions.html">db_cluster_runtime_versions()</a></code>.</p></dd>


<dt id="arg-node-type-id">node_type_id<a class="anchor" aria-label="anchor" href="#arg-node-type-id"></a></dt>
<dd><p>The node type for the worker nodes.
<code><a href="db_cluster_list_node_types.html">db_cluster_list_node_types()</a></code> can be used to see available node types.</p></dd>


<dt id="arg-num-workers">num_workers<a class="anchor" aria-label="anchor" href="#arg-num-workers"></a></dt>
<dd><p>Number of worker nodes that this cluster should have. A
cluster has one Spark driver and <code>num_workers</code> executors for a total of
<code>num_workers</code> + 1 Spark nodes.</p></dd>


<dt id="arg-autoscale">autoscale<a class="anchor" aria-label="anchor" href="#arg-autoscale"></a></dt>
<dd><p>Instance of <code><a href="cluster_autoscale.html">cluster_autoscale()</a></code>.</p></dd>


<dt id="arg-spark-conf">spark_conf<a class="anchor" aria-label="anchor" href="#arg-spark-conf"></a></dt>
<dd><p>Named list. An object containing a set of optional,
user-specified Spark configuration key-value pairs. You can also pass in a
string of extra JVM options to the driver and the executors via
<code>spark.driver.extraJavaOptions</code> and <code>spark.executor.extraJavaOptions</code>
respectively. E.g. <code>list("spark.speculation" = true, "spark.streaming.ui.retainedBatches" = 5)</code>.</p></dd>


<dt id="arg-cloud-attrs">cloud_attrs<a class="anchor" aria-label="anchor" href="#arg-cloud-attrs"></a></dt>
<dd><p>Attributes related to clusters running on specific cloud
provider. Defaults to <code><a href="aws_attributes.html">aws_attributes()</a></code>. Must be one of <code><a href="aws_attributes.html">aws_attributes()</a></code>,
<code><a href="azure_attributes.html">azure_attributes()</a></code>, <code><a href="gcp_attributes.html">gcp_attributes()</a></code>.</p></dd>


<dt id="arg-driver-node-type-id">driver_node_type_id<a class="anchor" aria-label="anchor" href="#arg-driver-node-type-id"></a></dt>
<dd><p>The node type of the Spark driver. This field is
optional; if unset, the driver node type will be set as the same value as
<code>node_type_id</code> defined above. <code><a href="db_cluster_list_node_types.html">db_cluster_list_node_types()</a></code> can be used to
see available node types.</p></dd>


<dt id="arg-custom-tags">custom_tags<a class="anchor" aria-label="anchor" href="#arg-custom-tags"></a></dt>
<dd><p>Named list. An object containing a set of tags for cluster
resources. Databricks tags all cluster resources with these tags in addition
to <code>default_tags</code>. Databricks allows at most 45 custom tags.</p></dd>


<dt id="arg-init-scripts">init_scripts<a class="anchor" aria-label="anchor" href="#arg-init-scripts"></a></dt>
<dd><p>Instance of <code><a href="init_script_info.html">init_script_info()</a></code>.</p></dd>


<dt id="arg-spark-env-vars">spark_env_vars<a class="anchor" aria-label="anchor" href="#arg-spark-env-vars"></a></dt>
<dd><p>Named list. User-specified environment variable
key-value pairs. In order to specify an additional set of
<code>SPARK_DAEMON_JAVA_OPTS</code>, we recommend appending them to
<code>$SPARK_DAEMON_JAVA_OPTS</code> as shown in the following example. This ensures
that all default Databricks managed environmental variables are included as
well. E.g. <code>{"SPARK_DAEMON_JAVA_OPTS": "$SPARK_DAEMON_JAVA_OPTS -Dspark.shuffle.service.enabled=true"}</code></p></dd>


<dt id="arg-autotermination-minutes">autotermination_minutes<a class="anchor" aria-label="anchor" href="#arg-autotermination-minutes"></a></dt>
<dd><p>Automatically terminates the cluster after it
is inactive for this time in minutes. If not set, this cluster will not be
automatically terminated. If specified, the threshold must be between 10 and
10000 minutes. You can also set this value to 0 to explicitly disable
automatic termination. Defaults to 120.</p></dd>


<dt id="arg-log-conf">log_conf<a class="anchor" aria-label="anchor" href="#arg-log-conf"></a></dt>
<dd><p>Instance of <code><a href="cluster_log_conf.html">cluster_log_conf()</a></code>.</p></dd>


<dt id="arg-ssh-public-keys">ssh_public_keys<a class="anchor" aria-label="anchor" href="#arg-ssh-public-keys"></a></dt>
<dd><p>List. SSH public key contents that will be added to each
Spark node in this cluster. The corresponding private keys can be used to
login with the user name ubuntu on port 2200. Up to 10 keys can be specified.</p></dd>


<dt id="arg-driver-instance-pool-id">driver_instance_pool_id<a class="anchor" aria-label="anchor" href="#arg-driver-instance-pool-id"></a></dt>
<dd><p>ID of the instance pool to use for the
driver node. You must also specify <code>instance_pool_id</code>. Optional.</p></dd>


<dt id="arg-instance-pool-id">instance_pool_id<a class="anchor" aria-label="anchor" href="#arg-instance-pool-id"></a></dt>
<dd><p>ID of the instance pool to use for cluster nodes. If
<code>driver_instance_pool_id</code> is present, <code>instance_pool_id</code> is used for worker
nodes only. Otherwise, it is used for both the driver and worker nodes.
Optional.</p></dd>


<dt id="arg-idempotency-token">idempotency_token<a class="anchor" aria-label="anchor" href="#arg-idempotency-token"></a></dt>
<dd><p>An optional token that can be used to guarantee the
idempotency of cluster creation requests. If an active cluster with the
provided token already exists, the request will not create a new cluster,
but it will return the ID of the existing cluster instead. The existence of a
cluster with the same token is not checked against terminated clusters. If
you specify the idempotency token, upon failure you can retry until the
request succeeds. Databricks guarantees that exactly one cluster will be
launched with that idempotency token. This token should have at most 64
characters.</p></dd>


<dt id="arg-enable-elastic-disk">enable_elastic_disk<a class="anchor" aria-label="anchor" href="#arg-enable-elastic-disk"></a></dt>
<dd><p>When enabled, this cluster will dynamically
acquire additional disk space when its Spark workers are running low on
disk space.</p></dd>


<dt id="arg-apply-policy-default-values">apply_policy_default_values<a class="anchor" aria-label="anchor" href="#arg-apply-policy-default-values"></a></dt>
<dd><p>Boolean (Default: <code>TRUE</code>), whether to use
policy default values for missing cluster attributes.</p></dd>


<dt id="arg-enable-local-disk-encryption">enable_local_disk_encryption<a class="anchor" aria-label="anchor" href="#arg-enable-local-disk-encryption"></a></dt>
<dd><p>Boolean (Default: <code>TRUE</code>), whether
encryption of disks locally attached to the cluster is enabled.</p></dd>


<dt id="arg-docker-image">docker_image<a class="anchor" aria-label="anchor" href="#arg-docker-image"></a></dt>
<dd><p>Instance of <code><a href="docker_image.html">docker_image()</a></code>.</p></dd>


<dt id="arg-policy-id">policy_id<a class="anchor" aria-label="anchor" href="#arg-policy-id"></a></dt>
<dd><p>String, ID of a cluster policy.</p></dd>


<dt id="arg-kind">kind<a class="anchor" aria-label="anchor" href="#arg-kind"></a></dt>
<dd><p>The kind of compute described by this compute specification.</p></dd>


<dt id="arg-data-security-mode">data_security_mode<a class="anchor" aria-label="anchor" href="#arg-data-security-mode"></a></dt>
<dd><p>Data security mode decides what data governance
model to use when accessing data from a cluster.</p></dd>


<dt id="arg-host">host<a class="anchor" aria-label="anchor" href="#arg-host"></a></dt>
<dd><p>Databricks workspace URL, defaults to calling <code><a href="db_host.html">db_host()</a></code>.</p></dd>


<dt id="arg-token">token<a class="anchor" aria-label="anchor" href="#arg-token"></a></dt>
<dd><p>Databricks workspace token, defaults to calling <code><a href="db_token.html">db_token()</a></code>.</p></dd>


<dt id="arg-perform-request">perform_request<a class="anchor" aria-label="anchor" href="#arg-perform-request"></a></dt>
<dd><p>If <code>TRUE</code> (default) the request is performed, if
<code>FALSE</code> the httr2 request is returned <em>without</em> being performed.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>Create a new Apache Spark cluster. This method acquires new instances from
the cloud provider if necessary. This method is asynchronous; the returned
<code>cluster_id</code> can be used to poll the cluster state (<code><a href="db_cluster_get.html">db_cluster_get()</a></code>).
When this method returns, the cluster is in a <code>PENDING</code> state. The cluster is
usable once it enters a <code>RUNNING</code> state.</p>
<p>Databricks may not be able to acquire some of the requested nodes, due to
cloud provider limitations or transient network issues. If Databricks
acquires at least 85% of the requested on-demand nodes, cluster creation will
succeed. Otherwise the cluster will terminate with an informative error
message.</p>
<p>Cannot specify both <code>autoscale</code> and <code>num_workers</code>, must choose one.</p>
<p><a href="https://docs.databricks.com/api/workspace/clusters/create" class="external-link">More Documentation</a>.</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p>Other Clusters API:
<code><a href="db_cluster_edit.html">db_cluster_edit()</a></code>,
<code><a href="db_cluster_events.html">db_cluster_events()</a></code>,
<code><a href="db_cluster_get.html">db_cluster_get()</a></code>,
<code><a href="db_cluster_list.html">db_cluster_list()</a></code>,
<code><a href="db_cluster_list_node_types.html">db_cluster_list_node_types()</a></code>,
<code><a href="db_cluster_list_zones.html">db_cluster_list_zones()</a></code>,
<code><a href="db_cluster_perm_delete.html">db_cluster_perm_delete()</a></code>,
<code><a href="db_cluster_pin.html">db_cluster_pin()</a></code>,
<code><a href="db_cluster_resize.html">db_cluster_resize()</a></code>,
<code><a href="db_cluster_restart.html">db_cluster_restart()</a></code>,
<code><a href="db_cluster_runtime_versions.html">db_cluster_runtime_versions()</a></code>,
<code><a href="db_cluster_start.html">db_cluster_start()</a></code>,
<code><a href="db_cluster_terminate.html">db_cluster_terminate()</a></code>,
<code><a href="db_cluster_unpin.html">db_cluster_unpin()</a></code>,
<code><a href="get_and_start_cluster.html">get_and_start_cluster()</a></code>,
<code><a href="get_latest_dbr.html">get_latest_dbr()</a></code></p></div>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/zacdav-db" class="external-link">Zac Davies</a>, <a href="https://www.linkedin.com/in/raphaelkurlansik/" class="external-link">Rafi Kurlansik</a>, <a href="https://www.databricks.com" class="external-link"><img src="https://databricks.com/wp-content/uploads/2019/12/cropped-databricks-icon-192x192.png" width="25" alt="Databricks"></a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>

